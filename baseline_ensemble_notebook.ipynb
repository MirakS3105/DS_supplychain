{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Baseline with Multiple Models & Ensemble\n",
    "\n",
    "This notebook tests multiple algorithms on baseline features to find the best performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# XGBoost and LightGBM\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from lightgbm import LGBMRegressor\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"LightGBM not installed. Install with: pip install lightgbm\")\n",
    "\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "def melt_wide_to_long(df, value_name='units_sold'):\n",
    "    \"\"\"Convert wide format to long format\"\"\"\n",
    "    id_cols = ['store_id', 'product_id']\n",
    "    date_cols = [col for col in df.columns if col not in id_cols]\n",
    "    melted = df.melt(id_vars=id_cols, value_vars=date_cols,\n",
    "                     var_name='date', value_name=value_name)\n",
    "    melted['date'] = pd.to_datetime(melted['date'])\n",
    "    melted[value_name] = pd.to_numeric(melted[value_name], errors='coerce')\n",
    "    return melted\n",
    "\n",
    "# Convert data\n",
    "train_long = melt_wide_to_long(train_df, 'units_sold')\n",
    "test_long = melt_wide_to_long(test_df, 'target')\n",
    "\n",
    "# Add basic features\n",
    "for df in [train_long, test_long]:\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "\n",
    "# Encode categoricals\n",
    "le_store = LabelEncoder()\n",
    "le_product = LabelEncoder()\n",
    "train_long['store_id_encoded'] = le_store.fit_transform(train_long['store_id'])\n",
    "train_long['product_id_encoded'] = le_product.fit_transform(train_long['product_id'])\n",
    "\n",
    "test_long['store_id_encoded'] = test_long['store_id'].map(\n",
    "    lambda x: le_store.transform([x])[0] if x in le_store.classes_ else -1)\n",
    "test_long['product_id_encoded'] = test_long['product_id'].map(\n",
    "    lambda x: le_product.transform([x])[0] if x in le_product.classes_ else -1)\n",
    "\n",
    "# Define features\n",
    "feature_cols = ['store_id_encoded', 'product_id_encoded', 'year', 'month', \n",
    "                'day', 'dayofweek', 'dayofyear']\n",
    "\n",
    "print(f\"Data prepared with {len(feature_cols)} features\")\n",
    "print(f\"Train: {len(train_long)} samples\")\n",
    "print(f\"Test: {len(test_long)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_clean = train_long.dropna(subset=['units_sold'])\n",
    "\n",
    "max_date = train_clean['date'].max()\n",
    "val_cutoff = max_date - pd.Timedelta(days=30)\n",
    "\n",
    "train_mask = train_clean['date'] <= val_cutoff\n",
    "val_mask = train_clean['date'] > val_cutoff\n",
    "\n",
    "X_train = train_clean[train_mask][feature_cols]\n",
    "y_train = train_clean[train_mask]['units_sold']\n",
    "X_val = train_clean[val_mask][feature_cols]\n",
    "y_val = train_clean[val_mask]['units_sold']\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Val: {len(X_val)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store models and results\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "print(\"1. Linear Regression...\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "models['LinearRegression'] = lr\n",
    "lr_val_pred = lr.predict(X_val)\n",
    "lr_mae = mean_absolute_error(y_val, lr_val_pred)\n",
    "lr_r2 = r2_score(y_val, lr_val_pred)\n",
    "results.append(['Linear Regression', lr_mae, lr_r2])\n",
    "print(f\"   MAE: {lr_mae:.4f}, R¬≤: {lr_r2:.4f}\\n\")\n",
    "\n",
    "# 2. Ridge Regression\n",
    "print(\"2. Ridge Regression...\")\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "models['Ridge'] = ridge\n",
    "ridge_val_pred = ridge.predict(X_val)\n",
    "ridge_mae = mean_absolute_error(y_val, ridge_val_pred)\n",
    "ridge_r2 = r2_score(y_val, ridge_val_pred)\n",
    "results.append(['Ridge Regression', ridge_mae, ridge_r2])\n",
    "print(f\"   MAE: {ridge_mae:.4f}, R¬≤: {ridge_r2:.4f}\\n\")\n",
    "\n",
    "# 3. Random Forest\n",
    "print(\"3. Random Forest...\")\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "models['RandomForest'] = rf\n",
    "rf_val_pred = rf.predict(X_val)\n",
    "rf_mae = mean_absolute_error(y_val, rf_val_pred)\n",
    "rf_r2 = r2_score(y_val, rf_val_pred)\n",
    "results.append(['Random Forest', rf_mae, rf_r2])\n",
    "print(f\"   MAE: {rf_mae:.4f}, R¬≤: {rf_r2:.4f}\\n\")\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "print(\"4. Gradient Boosting...\")\n",
    "gb = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "models['GradientBoosting'] = gb\n",
    "gb_val_pred = gb.predict(X_val)\n",
    "gb_mae = mean_absolute_error(y_val, gb_val_pred)\n",
    "gb_r2 = r2_score(y_val, gb_val_pred)\n",
    "results.append(['Gradient Boosting', gb_mae, gb_r2])\n",
    "print(f\"   MAE: {gb_mae:.4f}, R¬≤: {gb_r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. XGBoost (if available)\n",
    "if XGBOOST_AVAILABLE:\n",
    "    print(\"5. XGBoost...\")\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    models['XGBoost'] = xgb_model\n",
    "    xgb_val_pred = xgb_model.predict(X_val)\n",
    "    xgb_mae = mean_absolute_error(y_val, xgb_val_pred)\n",
    "    xgb_r2 = r2_score(y_val, xgb_val_pred)\n",
    "    results.append(['XGBoost', xgb_mae, xgb_r2])\n",
    "    print(f\"   MAE: {xgb_mae:.4f}, R¬≤: {xgb_r2:.4f}\\n\")\n",
    "else:\n",
    "    print(\"5. XGBoost - SKIPPED (not installed)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. LightGBM (if available)\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    print(\"6. LightGBM...\")\n",
    "    lgb_model = LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    models['LightGBM'] = lgb_model\n",
    "    lgb_val_pred = lgb_model.predict(X_val)\n",
    "    lgb_mae = mean_absolute_error(y_val, lgb_val_pred)\n",
    "    lgb_r2 = r2_score(y_val, lgb_val_pred)\n",
    "    results.append(['LightGBM', lgb_mae, lgb_r2])\n",
    "    print(f\"   MAE: {lgb_mae:.4f}, R¬≤: {lgb_r2:.4f}\\n\")\n",
    "else:\n",
    "    print(\"6. LightGBM - SKIPPED (not installed)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'MAE', 'R¬≤'])\n",
    "results_df = results_df.sort_values('MAE')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_mae = results_df.iloc[0]['MAE']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (MAE: {best_mae:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ensemble: average of top 3 models\n",
    "print(\"Creating Ensemble (Average of Top 3 Models)...\\n\")\n",
    "\n",
    "# Get top 3 models by MAE\n",
    "top_3_models = results_df.head(3)['Model'].tolist()\n",
    "print(f\"Top 3 models: {top_3_models}\")\n",
    "\n",
    "# Get predictions from top 3 models\n",
    "ensemble_predictions = []\n",
    "\n",
    "for model_name in top_3_models:\n",
    "    if model_name == 'Linear Regression':\n",
    "        pred = lr.predict(X_val)\n",
    "    elif model_name == 'Ridge Regression':\n",
    "        pred = ridge.predict(X_val)\n",
    "    elif model_name == 'Random Forest':\n",
    "        pred = rf.predict(X_val)\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        pred = gb.predict(X_val)\n",
    "    elif model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "        pred = xgb_model.predict(X_val)\n",
    "    elif model_name == 'LightGBM' and LIGHTGBM_AVAILABLE:\n",
    "        pred = lgb_model.predict(X_val)\n",
    "    else:\n",
    "        continue\n",
    "    ensemble_predictions.append(pred)\n",
    "\n",
    "# Average predictions\n",
    "ensemble_val_pred = np.mean(ensemble_predictions, axis=0)\n",
    "ensemble_mae = mean_absolute_error(y_val, ensemble_val_pred)\n",
    "ensemble_r2 = r2_score(y_val, ensemble_val_pred)\n",
    "\n",
    "print(f\"\\nEnsemble Performance:\")\n",
    "print(f\"  MAE: {ensemble_mae:.4f}\")\n",
    "print(f\"  R¬≤: {ensemble_r2:.4f}\")\n",
    "\n",
    "# Add to results\n",
    "results.append(['Ensemble (Top 3)', ensemble_mae, ensemble_r2])\n",
    "\n",
    "# Compare with best single model\n",
    "if ensemble_mae < best_mae:\n",
    "    print(f\"\\n‚úÖ Ensemble improved by {best_mae - ensemble_mae:.4f} MAE!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Best single model is better by {ensemble_mae - best_mae:.4f} MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted ensemble (weight by inverse of MAE)\n",
    "print(\"\\nCreating Weighted Ensemble...\\n\")\n",
    "\n",
    "# Get top 3 MAE values\n",
    "top_3_mae = results_df.head(3)['MAE'].values\n",
    "\n",
    "# Calculate weights (inverse of MAE, normalized)\n",
    "weights = 1 / top_3_mae\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "print(f\"Weights: {dict(zip(top_3_models, weights.round(4)))}\")\n",
    "\n",
    "# Weighted average\n",
    "weighted_val_pred = np.average(ensemble_predictions, axis=0, weights=weights)\n",
    "weighted_mae = mean_absolute_error(y_val, weighted_val_pred)\n",
    "weighted_r2 = r2_score(y_val, weighted_val_pred)\n",
    "\n",
    "print(f\"\\nWeighted Ensemble Performance:\")\n",
    "print(f\"  MAE: {weighted_mae:.4f}\")\n",
    "print(f\"  R¬≤: {weighted_r2:.4f}\")\n",
    "\n",
    "results.append(['Weighted Ensemble', weighted_mae, weighted_r2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final results\n",
    "final_results_df = pd.DataFrame(results, columns=['Model', 'MAE', 'R¬≤'])\n",
    "final_results_df = final_results_df.sort_values('MAE')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL RANKING\")\n",
    "print(\"=\"*60)\n",
    "print(final_results_df.to_string(index=False))\n",
    "\n",
    "# Best overall\n",
    "best_overall = final_results_df.iloc[0]\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_overall['Model']}\")\n",
    "print(f\"   MAE: {best_overall['MAE']:.4f}\")\n",
    "print(f\"   R¬≤:  {best_overall['R¬≤']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Best Model on Full Dataset & Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model on full dataset\n",
    "X_full = train_clean[feature_cols]\n",
    "y_full = train_clean['units_sold']\n",
    "\n",
    "best_model_type = best_overall['Model']\n",
    "print(f\"Training {best_model_type} on full dataset...\")\n",
    "\n",
    "if best_model_type == 'Linear Regression':\n",
    "    final_model = LinearRegression()\n",
    "elif best_model_type == 'Ridge Regression':\n",
    "    final_model = Ridge(alpha=1.0)\n",
    "elif best_model_type == 'Random Forest':\n",
    "    final_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "elif best_model_type == 'Gradient Boosting':\n",
    "    final_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "elif best_model_type == 'XGBoost':\n",
    "    final_model = xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "elif best_model_type == 'LightGBM':\n",
    "    final_model = LGBMRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "elif 'Ensemble' in best_model_type:\n",
    "    # For ensemble, train all top 3 models on full data\n",
    "    print(\"Training ensemble components on full dataset...\")\n",
    "    ensemble_models = []\n",
    "    for model_name in top_3_models:\n",
    "        if model_name == 'Linear Regression':\n",
    "            m = LinearRegression()\n",
    "        elif model_name == 'Ridge Regression':\n",
    "            m = Ridge(alpha=1.0)\n",
    "        elif model_name == 'Random Forest':\n",
    "            m = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "        elif model_name == 'Gradient Boosting':\n",
    "            m = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "        elif model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "            m = xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "        elif model_name == 'LightGBM' and LIGHTGBM_AVAILABLE:\n",
    "            m = LGBMRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "        m.fit(X_full, y_full)\n",
    "        ensemble_models.append(m)\n",
    "    final_model = None  # Special case\n",
    "else:\n",
    "    final_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "if final_model is not None:\n",
    "    final_model.fit(X_full, y_full)\n",
    "    print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "X_test = test_long[feature_cols]\n",
    "\n",
    "if 'Ensemble' in best_model_type:\n",
    "    # Ensemble prediction\n",
    "    test_preds = []\n",
    "    for m in ensemble_models:\n",
    "        test_preds.append(m.predict(X_test))\n",
    "    if 'Weighted' in best_model_type:\n",
    "        test_predictions = np.average(test_preds, axis=0, weights=weights)\n",
    "    else:\n",
    "        test_predictions = np.mean(test_preds, axis=0)\n",
    "else:\n",
    "    test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Ensure non-negative\n",
    "test_predictions = np.maximum(0, test_predictions)\n",
    "\n",
    "print(f\"Generated {len(test_predictions)} predictions\")\n",
    "print(f\"Range: {test_predictions.min():.2f} to {test_predictions.max():.2f}\")\n",
    "print(f\"Mean: {test_predictions.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = test_long[['store_id', 'product_id', 'date']].copy()\n",
    "submission['units_sold'] = test_predictions.round(2)\n",
    "submission['id'] = (\n",
    "    submission['store_id'] + '_' + \n",
    "    submission['product_id'] + '_' + \n",
    "    submission['date'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "submission = submission[['id', 'units_sold']]\n",
    "\n",
    "# Save with model name in filename\n",
    "filename = f\"submission_{best_model_type.replace(' ', '_').lower()}.csv\"\n",
    "submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved: {filename}\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook compared multiple models on baseline features:\n",
    "\n",
    "**Models Tested:**\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost (if installed)\n",
    "- LightGBM (if installed)\n",
    "- Ensemble (average of top 3)\n",
    "- Weighted Ensemble (weighted by inverse MAE)\n",
    "\n",
    "**Results:**\n",
    "- See the 'FINAL MODEL RANKING' table above\n",
    "- Best model is automatically selected and used for submission\n",
    "\n",
    "**Next Steps:**\n",
    "1. Note the baseline MAE from the best model\n",
    "2. Add feature engineering (lags, rolling, external data)\n",
    "3. See if you can beat this baseline score!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
