{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Supply Chain Demand Forecasting\n",
    "\n",
    "This is a simplified baseline notebook with NO feature engineering to establish a performance baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nTrain columns: {list(train_df.columns[:5])}... {list(train_df.columns[-3:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Wide to Long Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_wide_to_long(df, value_name='units_sold'):\n",
    "    \"\"\"Convert wide format to long format\"\"\"\n",
    "    # Get ID and date columns\n",
    "    id_cols = ['store_id', 'product_id']\n",
    "    date_cols = [col for col in df.columns if col not in id_cols]\n",
    "    \n",
    "    # Melt the dataframe\n",
    "    melted = df.melt(\n",
    "        id_vars=id_cols,\n",
    "        value_vars=date_cols,\n",
    "        var_name='date',\n",
    "        value_name=value_name\n",
    "    )\n",
    "    \n",
    "    # Convert to proper types\n",
    "    melted['date'] = pd.to_datetime(melted['date'])\n",
    "    melted[value_name] = pd.to_numeric(melted[value_name], errors='coerce')\n",
    "    \n",
    "    return melted\n",
    "\n",
    "# Convert train and test\n",
    "train_long = melt_wide_to_long(train_df, 'units_sold')\n",
    "test_long = melt_wide_to_long(test_df, 'target')\n",
    "\n",
    "print(f\"Train long shape: {train_long.shape}\")\n",
    "print(f\"Test long shape: {test_long.shape}\")\n",
    "print(f\"\\nTrain date range: {train_long['date'].min()} to {train_long['date'].max()}\")\n",
    "print(f\"Test date range: {test_long['date'].min()} to {test_long['date'].max()}\")\n",
    "print(f\"\\nSample train data:\")\n",
    "print(train_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimal Feature Engineering (Only Basic Time Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add only basic temporal features (no lag, no rolling, no complex features)\n",
    "def add_basic_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    return df\n",
    "\n",
    "# Apply to both datasets\n",
    "train_features = add_basic_time_features(train_long)\n",
    "test_features = add_basic_time_features(test_long)\n",
    "\n",
    "print(f\"Added basic time features\")\n",
    "print(f\"Features: {[c for c in train_features.columns if c not in ['store_id', 'product_id', 'date', 'units_sold']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_store = LabelEncoder()\n",
    "le_product = LabelEncoder()\n",
    "\n",
    "# Fit on train and transform both\n",
    "train_features['store_id_encoded'] = le_store.fit_transform(train_features['store_id'])\n",
    "train_features['product_id_encoded'] = le_product.fit_transform(train_features['product_id'])\n",
    "\n",
    "# For test, handle unseen categories\n",
    "test_features['store_id_encoded'] = test_features['store_id'].map(\n",
    "    lambda x: le_store.transform([x])[0] if x in le_store.classes_ else -1\n",
    ")\n",
    "test_features['product_id_encoded'] = test_features['product_id'].map(\n",
    "    lambda x: le_product.transform([x])[0] if x in le_product.classes_ else -1\n",
    ")\n",
    "\n",
    "print(\"Categorical variables encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (minimal - no lag, no rolling)\n",
    "feature_cols = [\n",
    "    'store_id_encoded',\n",
    "    'product_id_encoded',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'dayofweek',\n",
    "    'dayofyear'\n",
    "]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features: {feature_cols}\")\n",
    "\n",
    "# Prepare training data\n",
    "train_clean = train_features.dropna(subset=['units_sold'])\n",
    "\n",
    "X = train_clean[feature_cols]\n",
    "y = train_clean['units_sold']\n",
    "\n",
    "print(f\"\\nTraining samples: {len(X)}\")\n",
    "print(f\"Target range: {y.min():.0f} to {y.max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train-Validation Split (Time-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: Use last 30 days as validation\n",
    "max_date = train_clean['date'].max()\n",
    "val_cutoff = max_date - pd.Timedelta(days=30)\n",
    "\n",
    "train_mask = train_clean['date'] <= val_cutoff\n",
    "val_mask = train_clean['date'] > val_cutoff\n",
    "\n",
    "X_train, X_val = X[train_mask], X[val_mask]\n",
    "y_train, y_val = y[train_mask], y[val_mask]\n",
    "\n",
    "print(f\"Training period: {train_clean[train_mask]['date'].min()} to {train_clean[train_mask]['date'].max()}\")\n",
    "print(f\"Validation period: {train_clean[val_mask]['date'].min()} to {train_clean[val_mask]['date'].max()}\")\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple Random Forest model\n",
    "print(\"Training baseline Random Forest model...\")\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=50,  # Small for speed\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "train_pred = model.predict(X_train)\n",
    "val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train, train_pred)\n",
    "val_mae = mean_absolute_error(y_val, val_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "\n",
    "train_r2 = r2_score(y_train, train_pred)\n",
    "val_r2 = r2_score(y_val, val_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE MODEL PERFORMANCE (NO FEATURE ENGINEERING)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  MAE:  {train_mae:.4f}\")\n",
    "print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  MAE:  {val_mae:.4f}\")\n",
    "print(f\"  RMSE: {val_rmse:.4f}\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nOverfitting Check:\")\n",
    "print(f\"  Val MAE / Train MAE = {val_mae/train_mae:.2f}\")\n",
    "if val_mae/train_mae > 1.2:\n",
    "    print(\"  ⚠️  Model may be overfitting\")\n",
    "else:\n",
    "    print(\"  ✅ Good generalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Predictions for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full dataset for submission\n",
    "print(\"Training on full dataset...\")\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_features[feature_cols]\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Ensure non-negative predictions\n",
    "test_predictions = np.maximum(0, test_predictions)\n",
    "\n",
    "print(f\"Generated {len(test_predictions)} predictions\")\n",
    "print(f\"Prediction range: {test_predictions.min():.2f} to {test_predictions.max():.2f}\")\n",
    "print(f\"Mean prediction: {test_predictions.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = test_features[['store_id', 'product_id', 'date']].copy()\n",
    "submission['units_sold'] = test_predictions\n",
    "\n",
    "# Create ID column\n",
    "submission['id'] = (\n",
    "    submission['store_id'] + '_' + \n",
    "    submission['product_id'] + '_' + \n",
    "    submission['date'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "# Round predictions\n",
    "submission['units_sold'] = submission['units_sold'].round(2)\n",
    "\n",
    "# Keep only required columns\n",
    "submission = submission[['id', 'units_sold']]\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(submission.head())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission_baseline.csv', index=False)\n",
    "print(\"\\nSaved to: submission_baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This baseline model:\n",
    "- Uses only 7 basic features (store_id, product_id, year, month, day, dayofweek, dayofyear)\n",
    "- NO lag features\n",
    "- NO rolling statistics\n",
    "- NO external data (prices, weather, promotions, etc.)\n",
    "- NO advanced feature engineering\n",
    "\n",
    "**Baseline Performance:**\n",
    "- Validation MAE: `{val_mae:.4f}`\n",
    "- Validation R²: `{val_r2:.4f}`\n",
    "\n",
    "This is your starting point. Now you can:\n",
    "1. Add lag features and see if MAE improves\n",
    "2. Add rolling statistics\n",
    "3. Include external data (prices, discounts, etc.)\n",
    "4. Use more sophisticated models\n",
    "\n",
    "Each improvement should result in a lower MAE score!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
